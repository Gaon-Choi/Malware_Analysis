from lightgbm import LGBMClassifier
import lightgbm

import pandas as pd
import numpy as np

from sklearn.preprocessing import LabelEncoder

train_dataset = pd.read_csv('./dataset/train.csv')
valid_dataset = pd.read_csv('./dataset/valid.csv')
test1_dataset = pd.read_csv('./dataset/test1.csv')
test2_dataset = pd.read_csv('./dataset/test2.csv')

label_columns = [
    'type_description',
    'best_trid_type',
    'type_extension',
    'overlay_filetype',
    'packer',
    'type_tag'
]
train_len = len(train_dataset)
valid_len = len(valid_dataset)
test1_len = len(test1_dataset)
test2_len = len(test2_dataset)

df = pd.concat([train_dataset, valid_dataset, test1_dataset, test2_dataset])
df['is_mal'] = df['is_mal'].astype(np.int8)
print(df['is_mal'])
from tqdm import tqdm
for column in label_columns:
    label_encoder = LabelEncoder()
    df[column] = label_encoder.fit_transform(df[column]).astype(np.int8)

train_dataset = df[:train_len]
valid_dataset = df[train_len:train_len+valid_len]
test1_dataset = df[train_len+valid_len:train_len+valid_len+test1_len]
test2_dataset = df[train_len+valid_len+test1_len:train_len+valid_len+test1_len+test2_len]

def oversampling(df: pd.DataFrame):
    # Oversampling so that the distribution of is_mal is the same
    df_mal = df[df['is_mal'] == 1]
    df_not_mal = df[df['is_mal'] == 0]
    df_not_mal_len = len(df_not_mal)
    df_mal_len = len(df_mal)

    if df_not_mal_len < df_mal_len:
        df_not_mal_oversampled = df_not_mal.sample(n=df_mal_len, replace=True)
        df_oversampled = pd.concat([df_not_mal_oversampled, df_mal], ignore_index=True)
        return df_oversampled
    else:
        df_mal_oversampled = df_mal.sample(n=df_not_mal_len, replace=True)
        df_oversampled = pd.concat([df_mal_oversampled, df_not_mal], ignore_index=True)
        return df_oversampled

print(train_dataset)
print(valid_dataset)
print(test1_dataset)
print(test2_dataset)

train_dataset = oversampling(train_dataset)
valid_dataset = oversampling(valid_dataset)
test1_dataset = oversampling(test1_dataset)
test2_dataset = oversampling(test2_dataset)

train_x = train_dataset.loc[:, ~train_dataset.columns.isin(['is_mal', 'hash', 'best_trid_probability', 'behaviours_count', 'dropped_files_count'])]
print(train_x)
# exit()
train_y = train_dataset.loc[:, 'is_mal'].values

valid_x = valid_dataset.loc[:, ~valid_dataset.columns.isin(['is_mal', 'hash', 'best_trid_probability', 'behaviours_count', 'dropped_files_count'])]
valid_y = valid_dataset.loc[:, 'is_mal'].values

test1_x = test1_dataset.loc[:, ~test1_dataset.columns.isin(['is_mal', 'hash', 'best_trid_probability', 'behaviours_count', 'dropped_files_count'])]
test1_y = test1_dataset.loc[:, 'is_mal'].values

test2_x = test2_dataset.loc[:, ~test2_dataset.columns.isin(['is_mal', 'hash', 'best_trid_probability', 'behaviours_count', 'dropped_files_count'])]
test2_y = test2_dataset.loc[:, 'is_mal'].values
evals = [(valid_x, valid_y)]
# evals = [(train_x, train_y)]

print(len(train_y[train_y == 0]) / len(train_y))
lgbm = LGBMClassifier(n_estimators=4000)
# lgbm.fit(train_x, train_y, early_stopping_rounds=1000, eval_set=(train_x, train_y))

preds_1 = lgbm
lgbm.fit(train_x, train_y, early_stopping_rounds=10, eval_set=evals)
preds_train = lgbm.predict(train_x)
preds_valid = lgbm.predict(valid_x)
preds_test1 = lgbm.predict(test1_x)
preds_test2 = lgbm.predict(test2_x)
# lightgbm.plot_tree(lgbm, dpi=1000).get_figure().savefig('tree.png')

from sklearn.metrics import *
def get_clf_eval(y_test, pred=None, pred_proba=None): 
    pred_binary = []
    for i in pred:
        pred_binary.append(i > .5)
    pred = pred_binary
    confusion = confusion_matrix(y_test, pred) 
    accuracy = accuracy_score(y_test, pred) 
    precision = precision_score(y_test, pred) 
    recall = recall_score(y_test, pred) 
    f1 = f1_score(y_test, pred) 
    # ROC AUC 
    # roc_auc = roc_auc_score(y_test, pred_proba) 
    roc_auc = 1
    print('Confusion Matrix') 
    print(confusion) 
    print('accuracy: {0:.4f}, precision: {1:.4f}, recall: {2:.4f}, f1: {3:.4f}, roc_auc: {4:.4f}'.format( accuracy, precision, recall, f1, roc_auc))
    
get_clf_eval(train_y, preds_train)
get_clf_eval(valid_y, preds_valid)
# print(preds_1)
get_clf_eval(test1_y, preds_test1)
get_clf_eval(test2_y, preds_test2)

from lightgbm import plot_importance

plot_importance(lgbm).figure.savefig('important.png', dpi=300, bbox_inches='tight')